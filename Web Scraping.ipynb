{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing BeautifulSoup library which is used to extract data from html files and \n",
    "urlopen is used to open the URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the data from the given url and passed it to urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.hubertiming.com/results/2017GPTR10K\"\n",
    "html = urlopen(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    By Performing above step we got the html page. \n",
    "    Now we will create BeautifulSoup Object from html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(html, 'lxml')\n",
    "type(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Creating BeautifulSoup Object will allow us to interact with the tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>2017 Intel Great Place to Run 10K \\ Urban Clash Games Race Results</title>\n"
     ]
    }
   ],
   "source": [
    "print(soup.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text = soup.get_text()\\nprint(soup.text)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"text = soup.get_text()\n",
    "print(soup.text)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"btn btn-primary btn-lg\" href=\"/results/2017GPTR\" role=\"button\" style=\"margin: 0px 0px 5px 5px\">5K</a>,\n",
       " <a href=\"https://www.hubertiming.com/\">Huber Timing Home</a>,\n",
       " <a href=\"#individual\">Individual Results</a>,\n",
       " <a href=\"#team\">Team Results</a>,\n",
       " <a href=\"mailto:timing@hubertiming.com\">timing@hubertiming.com</a>,\n",
       " <a href=\"#tabs-1\" style=\"font-size: 18px\">Results</a>,\n",
       " <a name=\"individual\"></a>,\n",
       " <a name=\"team\"></a>,\n",
       " <a href=\"https://www.hubertiming.com/\"><img height=\"65\" src=\"/sites/all/themes/hubertiming/images/clockWithFinishSign_small.png\" width=\"50\"/>Huber Timing</a>,\n",
       " <a href=\"https://facebook.com/hubertiming/\"><img src=\"/results/FB-f-Logo__blue_50.png\"/></a>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here the a tag used to get hyperlinks.But we can see that it contains additional attributes such as src, class etc.\n",
    "\n",
    "soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/results/2017GPTR\n",
      "https://www.hubertiming.com/\n",
      "#individual\n",
      "#team\n",
      "mailto:timing@hubertiming.com\n",
      "#tabs-1\n",
      "None\n",
      "None\n",
      "https://www.hubertiming.com/\n",
      "https://facebook.com/hubertiming/\n"
     ]
    }
   ],
   "source": [
    "# Now we will extract only hyperlinks i.e. href\n",
    "all_links = soup.find_all('a')\n",
    "for link in all_links:\n",
    "    print(link.get(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tr><td>Finishers:</td><td>577</td></tr>, <tr><td>Male:</td><td>414</td></tr>, <tr><td>Female:</td><td>163</td></tr>, <tr class=\"header\">\n",
      "<th>Place</th>\n",
      "<th>Bib</th>\n",
      "<th>Name</th>\n",
      "<th>Gender</th>\n",
      "<th>City</th>\n",
      "<th>State</th>\n",
      "<th>Chip Time</th>\n",
      "<th>Chip Pace</th>\n",
      "<th>Gender Place</th>\n",
      "<th>Age Group</th>\n",
      "<th>Age Group Place</th>\n",
      "<th>Time to Start</th>\n",
      "<th>Gun Time</th>\n",
      "<th>Team</th>\n",
      "</tr>, <tr>\n",
      "<td>1</td>\n",
      "<td>814</td>\n",
      "<td>JARED WILSON</td>\n",
      "<td>M</td>\n",
      "<td>TIGARD</td>\n",
      "<td>OR</td>\n",
      "<td>00:36:21</td>\n",
      "<td>05:51</td>\n",
      "<td>1 of 414</td>\n",
      "<td>M 36-45</td>\n",
      "<td>1 of 152</td>\n",
      "<td>00:00:03</td>\n",
      "<td>00:36:24</td>\n",
      "<td></td>\n",
      "</tr>, <tr>\n",
      "<td>2</td>\n",
      "<td>573</td>\n",
      "<td>NATHAN A SUSTERSIC</td>\n",
      "<td>M</td>\n",
      "<td>PORTLAND</td>\n",
      "<td>OR</td>\n",
      "<td>00:36:42</td>\n",
      "<td>05:55</td>\n",
      "<td>2 of 414</td>\n",
      "<td>M 26-35</td>\n",
      "<td>1 of 154</td>\n",
      "<td>00:00:03</td>\n",
      "<td>00:36:45</td>\n",
      "<td>INTEL TEAM F</td>\n",
      "</tr>, <tr>\n",
      "<td>3</td>\n",
      "<td>687</td>\n",
      "<td>FRANCISCO MAYA</td>\n",
      "<td>M</td>\n",
      "<td>PORTLAND</td>\n",
      "<td>OR</td>\n",
      "<td>00:37:44</td>\n",
      "<td>06:05</td>\n",
      "<td>3 of 414</td>\n",
      "<td>M 46-55</td>\n",
      "<td>1 of 64</td>\n",
      "<td>00:00:04</td>\n",
      "<td>00:37:48</td>\n",
      "<td></td>\n",
      "</tr>, <tr>\n",
      "<td>4</td>\n",
      "<td>623</td>\n",
      "<td>PAUL MORROW</td>\n",
      "<td>M</td>\n",
      "<td>BEAVERTON</td>\n",
      "<td>OR</td>\n",
      "<td>00:38:34</td>\n",
      "<td>06:13</td>\n",
      "<td>4 of 414</td>\n",
      "<td>M 36-45</td>\n",
      "<td>2 of 152</td>\n",
      "<td>00:00:03</td>\n",
      "<td>00:38:37</td>\n",
      "<td></td>\n",
      "</tr>, <tr>\n",
      "<td>5</td>\n",
      "<td>569</td>\n",
      "<td>DEREK G OSBORNE</td>\n",
      "<td>M</td>\n",
      "<td>HILLSBORO</td>\n",
      "<td>OR</td>\n",
      "<td>00:39:21</td>\n",
      "<td>06:20</td>\n",
      "<td>5 of 414</td>\n",
      "<td>M 26-35</td>\n",
      "<td>2 of 154</td>\n",
      "<td>00:00:03</td>\n",
      "<td>00:39:24</td>\n",
      "<td>INTEL TEAM F</td>\n",
      "</tr>, <tr>\n",
      "<td>6</td>\n",
      "<td>642</td>\n",
      "<td>JONATHON TRAN</td>\n",
      "<td>M</td>\n",
      "<td>PORTLAND</td>\n",
      "<td>OR</td>\n",
      "<td>00:39:49</td>\n",
      "<td>06:25</td>\n",
      "<td>6 of 414</td>\n",
      "<td>M 18-25</td>\n",
      "<td>1 of 34</td>\n",
      "<td>00:00:06</td>\n",
      "<td>00:39:55</td>\n",
      "<td></td>\n",
      "</tr>]\n"
     ]
    }
   ],
   "source": [
    "# Here we extract the first 10 table rows\n",
    "rows = soup.find_all('tr')\n",
    "print(rows[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<td>14TH</td>, <td>INTEL TEAM M</td>, <td>04:43:23</td>, <td>00:58:59 - DANIELLE CASILLAS</td>, <td>01:02:06 - RAMYA MERUVA</td>, <td>01:17:06 - PALLAVI J SHINDE</td>, <td>01:25:11 - NALINI MURARI</td>]\n"
     ]
    }
   ],
   "source": [
    "for row in rows:\n",
    "    row_td = row.find_all('td')\n",
    "print(row_td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.ResultSet"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(row_td)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    We need to convert above table to dataframe.\n",
    "    Also we need to remove html tags.For that we can either use regular expressions or BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14TH, INTEL TEAM M, 04:43:23, 00:58:59 - DANIELLE CASILLAS, 01:02:06 - RAMYA MERUVA, 01:17:06 - PALLAVI J SHINDE, 01:25:11 - NALINI MURARI]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_cells = str(row_td)\n",
    "cleantext = BeautifulSoup(str_cells,'lxml').get_text()\n",
    "print(cleantext)\n",
    "type(cleantext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
